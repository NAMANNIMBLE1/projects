{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c1defe3c-c2af-4c1a-8f78-5f5d6dbd6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import tensorflow \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense , Input , Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "79b1b7fa-9b52-41a6-ba33-ec53e6c98b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\nex20\\\\Downloads\\\\archive\\\\Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "86a64bec-29f7-4bc9-9786-fd6677283818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  Chance of Admit \n",
       "0             1        337          118                  4  4.5   4.5  9.65         1              0.92\n",
       "1             2        324          107                  4  4.0   4.5  8.87         1              0.76\n",
       "2             3        316          104                  3  3.0   3.5  8.00         1              0.72\n",
       "3             4        322          110                  3  3.5   2.5  8.67         1              0.80\n",
       "4             5        314          103                  2  2.0   3.0  8.21         0              0.65\n",
       "..          ...        ...          ...                ...  ...   ...   ...       ...               ...\n",
       "395         396        324          110                  3  3.5   3.5  9.04         1              0.82\n",
       "396         397        325          107                  3  3.0   3.5  9.11         1              0.84\n",
       "397         398        330          116                  4  5.0   4.5  9.45         1              0.91\n",
       "398         399        312          103                  3  3.5   4.0  8.78         0              0.67\n",
       "399         400        333          117                  4  5.0   4.0  9.66         1              0.95\n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d53fc11c-5471-4963-9fa3-81058bfcc604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  Chance of Admit \n",
       "0           1        337          118                  4  4.5   4.5  9.65         1              0.92\n",
       "1           2        324          107                  4  4.0   4.5  8.87         1              0.76\n",
       "2           3        316          104                  3  3.0   3.5  8.00         1              0.72\n",
       "3           4        322          110                  3  3.5   2.5  8.67         1              0.80\n",
       "4           5        314          103                  2  2.0   3.0  8.21         0              0.65"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6b67965f-1b13-4a8f-9090-e1c482aa9ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7124d8a8-ca8d-476b-b847-6d6e049011e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         400 non-null    int64  \n",
      " 1   GRE Score          400 non-null    int64  \n",
      " 2   TOEFL Score        400 non-null    int64  \n",
      " 3   University Rating  400 non-null    int64  \n",
      " 4   SOP                400 non-null    float64\n",
      " 5   LOR                400 non-null    float64\n",
      " 6   CGPA               400 non-null    float64\n",
      " 7   Research           400 non-null    int64  \n",
      " 8   Chance of Admit    400 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 28.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8da3721b-e887-4b7e-9a31-e167b05688ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "53233cb5-af15-4595-8e2f-0e5ebcca3713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Serial No.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097526</td>\n",
       "      <td>-0.147932</td>\n",
       "      <td>-0.169948</td>\n",
       "      <td>-0.166932</td>\n",
       "      <td>-0.088221</td>\n",
       "      <td>-0.045608</td>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.042336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>-0.097526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.802610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>-0.147932</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.791594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>-0.169948</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.711250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>-0.166932</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.675732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>-0.088221</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.669889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>-0.045608</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>0.873289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.042336</td>\n",
       "      <td>0.802610</td>\n",
       "      <td>0.791594</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.669889</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Serial No.  GRE Score  TOEFL Score  ...      CGPA  Research  Chance of Admit \n",
       "Serial No.           1.000000  -0.097526    -0.147932  ... -0.045608 -0.063138          0.042336\n",
       "GRE Score           -0.097526   1.000000     0.835977  ...  0.833060  0.580391          0.802610\n",
       "TOEFL Score         -0.147932   0.835977     1.000000  ...  0.828417  0.489858          0.791594\n",
       "University Rating   -0.169948   0.668976     0.695590  ...  0.746479  0.447783          0.711250\n",
       "SOP                 -0.166932   0.612831     0.657981  ...  0.718144  0.444029          0.675732\n",
       "LOR                 -0.088221   0.557555     0.567721  ...  0.670211  0.396859          0.669889\n",
       "CGPA                -0.045608   0.833060     0.828417  ...  1.000000  0.521654          0.873289\n",
       "Research            -0.063138   0.580391     0.489858  ...  0.521654  1.000000          0.553202\n",
       "Chance of Admit      0.042336   0.802610     0.791594  ...  0.873289  0.553202          1.000000\n",
       "\n",
       "[9 rows x 9 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6cecc712-fe42-467d-865b-7b4f10c348dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6ad442c6-000b-4e0c-a479-558a33393fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'] , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5b7879ee-8d64-4870-9f7a-336df1e9dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[: ,  0 : -1]\n",
    "y = df.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0cedbad8-9b1b-4755-a9d2-cf127a99f9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e0170fda-ad29-4300-93c9-2ebd342e77d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "395    0.82\n",
       "396    0.84\n",
       "397    0.91\n",
       "398    0.67\n",
       "399    0.95\n",
       "Name: Chance of Admit , Length: 400, dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d79b580c-8e35-4c8e-866f-9776c22dc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "126f8f30-a1cf-4fa7-9639-a1a8be88c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled  = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e93e3a9b-1add-4638-afd9-77ede862471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nex20\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7 , activation= 'relu' , input_dim = 7))\n",
    "model.add(Dense(7 , activation= 'relu'))\n",
    "model.add(Dense(1 , activation = 'linear')) # for regression models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "73577560-2be6-45bd-9b23-67303dbf68a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d0de21eb-6d8f-4320-ac44-d129a4bdd870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4d754a43-9b8d-4055-b818-7addc8ba113f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 2.8693 - val_accuracy: 0.0000e+00 - val_loss: 2.1502\n",
      "Epoch 2/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 2.4951 - val_accuracy: 0.0000e+00 - val_loss: 1.8479\n",
      "Epoch 3/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 2.1219 - val_accuracy: 0.0000e+00 - val_loss: 1.5877\n",
      "Epoch 4/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 1.8559 - val_accuracy: 0.0000e+00 - val_loss: 1.3662\n",
      "Epoch 5/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 1.6174 - val_accuracy: 0.0000e+00 - val_loss: 1.1774\n",
      "Epoch 6/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 1.3596 - val_accuracy: 0.0000e+00 - val_loss: 1.0181\n",
      "Epoch 7/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 1.2382 - val_accuracy: 0.0000e+00 - val_loss: 0.8829\n",
      "Epoch 8/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1.1543 - val_accuracy: 0.0000e+00 - val_loss: 0.7626\n",
      "Epoch 9/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.9165 - val_accuracy: 0.0000e+00 - val_loss: 0.6462\n",
      "Epoch 10/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.8100 - val_accuracy: 0.0000e+00 - val_loss: 0.5303\n",
      "Epoch 11/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 0.6745 - val_accuracy: 0.0000e+00 - val_loss: 0.4213\n",
      "Epoch 12/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.5256 - val_accuracy: 0.0000e+00 - val_loss: 0.3180\n",
      "Epoch 13/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.4037 - val_accuracy: 0.0000e+00 - val_loss: 0.2309\n",
      "Epoch 14/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.3018 - val_accuracy: 0.0000e+00 - val_loss: 0.1622\n",
      "Epoch 15/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.2239 - val_accuracy: 0.0000e+00 - val_loss: 0.1127\n",
      "Epoch 16/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 0.1495 - val_accuracy: 0.0000e+00 - val_loss: 0.0811\n",
      "Epoch 17/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.1135 - val_accuracy: 0.0000e+00 - val_loss: 0.0617\n",
      "Epoch 18/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0837 - val_accuracy: 0.0000e+00 - val_loss: 0.0490\n",
      "Epoch 19/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0677 - val_accuracy: 0.0000e+00 - val_loss: 0.0393\n",
      "Epoch 20/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0504 - val_accuracy: 0.0000e+00 - val_loss: 0.0318\n",
      "Epoch 21/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0376 - val_accuracy: 0.0000e+00 - val_loss: 0.0257\n",
      "Epoch 22/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0301 - val_accuracy: 0.0000e+00 - val_loss: 0.0208\n",
      "Epoch 23/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0245 - val_accuracy: 0.0000e+00 - val_loss: 0.0171\n",
      "Epoch 24/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0197 - val_accuracy: 0.0000e+00 - val_loss: 0.0144\n",
      "Epoch 25/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0155 - val_accuracy: 0.0000e+00 - val_loss: 0.0125\n",
      "Epoch 26/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0135 - val_accuracy: 0.0000e+00 - val_loss: 0.0113\n",
      "Epoch 27/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0127 - val_accuracy: 0.0000e+00 - val_loss: 0.0105\n",
      "Epoch 28/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0109 - val_accuracy: 0.0000e+00 - val_loss: 0.0099\n",
      "Epoch 29/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0097 - val_accuracy: 0.0000e+00 - val_loss: 0.0096\n",
      "Epoch 30/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0097 - val_accuracy: 0.0000e+00 - val_loss: 0.0094\n",
      "Epoch 31/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0085 - val_accuracy: 0.0000e+00 - val_loss: 0.0092\n",
      "Epoch 32/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0097 - val_accuracy: 0.0000e+00 - val_loss: 0.0091\n",
      "Epoch 33/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0096 - val_accuracy: 0.0000e+00 - val_loss: 0.0090\n",
      "Epoch 34/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0086 - val_accuracy: 0.0000e+00 - val_loss: 0.0089\n",
      "Epoch 35/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0087 - val_accuracy: 0.0000e+00 - val_loss: 0.0088\n",
      "Epoch 36/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0079 - val_accuracy: 0.0000e+00 - val_loss: 0.0087\n",
      "Epoch 37/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0079 - val_accuracy: 0.0000e+00 - val_loss: 0.0087\n",
      "Epoch 38/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0084 - val_accuracy: 0.0000e+00 - val_loss: 0.0086\n",
      "Epoch 39/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0080 - val_accuracy: 0.0000e+00 - val_loss: 0.0085\n",
      "Epoch 40/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0080 - val_accuracy: 0.0000e+00 - val_loss: 0.0085\n",
      "Epoch 41/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0085\n",
      "Epoch 42/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0084\n",
      "Epoch 43/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0075 - val_accuracy: 0.0000e+00 - val_loss: 0.0083\n",
      "Epoch 44/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 0.0073 - val_accuracy: 0.0000e+00 - val_loss: 0.0083\n",
      "Epoch 45/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 0.0083 - val_accuracy: 0.0000e+00 - val_loss: 0.0082\n",
      "Epoch 46/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 0.0073 - val_accuracy: 0.0000e+00 - val_loss: 0.0082\n",
      "Epoch 47/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0081\n",
      "Epoch 48/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0081\n",
      "Epoch 49/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 0.0081\n",
      "Epoch 50/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 0.0080\n",
      "Epoch 51/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 52/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 0.0080 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 53/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 0.0079 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 54/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 0.0071 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 55/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0076 - val_accuracy: 0.0000e+00 - val_loss: 0.0078\n",
      "Epoch 56/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0077\n",
      "Epoch 57/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0063 - val_accuracy: 0.0000e+00 - val_loss: 0.0077\n",
      "Epoch 58/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0071 - val_accuracy: 0.0000e+00 - val_loss: 0.0077\n",
      "Epoch 59/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 0.0076\n",
      "Epoch 60/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0076\n",
      "Epoch 61/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0074 - val_accuracy: 0.0000e+00 - val_loss: 0.0075\n",
      "Epoch 62/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0075\n",
      "Epoch 63/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 0.0075\n",
      "Epoch 64/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0075\n",
      "Epoch 65/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 66/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 67/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 68/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 0.0073\n",
      "Epoch 69/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0073\n",
      "Epoch 70/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0073\n",
      "Epoch 71/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0061 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 72/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0067 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 73/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 74/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 75/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0056 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 76/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 77/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 78/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 79/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 80/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 81/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0057 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 82/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 83/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 84/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0053 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 85/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 86/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0051 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 87/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0061 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 88/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 89/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 90/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 91/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 92/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 93/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 94/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0067 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 95/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 96/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 97/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0061 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 98/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 99/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 100/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 101/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0069 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 102/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 103/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 104/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0051 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 105/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 106/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 107/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 108/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 109/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 110/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 111/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0064 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 112/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 113/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 0.0046 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 114/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 115/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 116/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 117/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0053 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 118/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 119/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 120/120\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled , y_train , epochs= 120 , validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "38861f88-ca27-4ea4-87b2-298224503f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22153886480>]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "dfa904ac-ddbb-4491-997d-58ea276abe5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2094851b-1580-4529-9d76-0d9b2647cd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7061318181168676\n",
      "0.0572939060330391\n",
      "0.005050939451488952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score , mean_absolute_error , mean_squared_error \n",
    "\n",
    "print(r2_score(y_pred , y_test))\n",
    "print(mean_absolute_error(y_pred , y_test))\n",
    "print(mean_squared_error(y_pred , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16baf09-5992-43b3-a76f-66d33f928796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
